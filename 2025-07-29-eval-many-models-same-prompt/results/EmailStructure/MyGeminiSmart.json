{"subject": "Cracking the Prompting Interview - Session Recap", "body": "Hello First Name,\n\nThis week's \ud83e\udd84 ai that works session was on \"Cracking the Prompting Interview\"!\n\nThe full recording, code, and diagrams from the session are now available on GitHub:\nhttps://github.com/hellovai/ai-that-works\n\nWe covered a lot on prompt engineering techniques and LLM optimization strategies. Here\u2019s a super quick recap:\n\n- **Think Like a Systems Engineer:** The best results come from treating the LLM as one component in a larger system. Offload complex generation or formatting to deterministic code, and have the LLM do what it does best: reasoning and understanding language.\n- **Optimize for Efficiency and Control:** Reduce token usage and improve accuracy by having the LLM output simple indexes or aliases instead of full text. You can also use inline comments within your prompt to guide the model's reasoning process without cluttering the final output.\n\nIf you remember one thing from this session:\nRTFP (Read The Full Prompt). Before you spend hours debugging your code or the model, stop and carefully re-read your prompt. The most common source of error is the LLM interpreting your instructions differently than you intended. Always verify your understanding first!\n\nOur next session on July 15th, 2025 will be all about \"Generating AI-powered Content with LLMs\" \u2013 exploring how to use LLMs to generate content for various use cases.", "call_to_action": "Sign up here: https://lu.ma/ai-that-works-12\n\nIf you have any questions, reply to this email or ask on Discord: https://www.boundaryml.com/discord. We read every message! Happy coding \ud83e\uddd1\u200d\ud83d\udcbb\n\nVaibhav & Dex"}