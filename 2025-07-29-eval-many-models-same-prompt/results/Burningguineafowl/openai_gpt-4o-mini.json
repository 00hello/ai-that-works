{"subject": "\ud83e\udd84 ai that works: Advanced Prompting & LLM Optimization Recap", "body": "Hello First Name,\n\nThis week's \ud83e\udd84 ai that works session was all about \"Advanced Prompting Techniques & LLM Optimization Strategies\"!\n\nThe full recording, code, and diagrams from the session are now available on GitHub:\nhttps://github.com/hellovai/ai-that-works\n\nWe covered a lot on how to build more efficient and reliable systems with LLMs. Here\u2019s a super quick recap:\n\nTreat your LLM as a reasoning engine, not an all-in-one computer. Shift complex logic, calculations, or strict formatting tasks to deterministic code. This makes your system more reliable. To reduce token usage and cost, have the LLM output lightweight indexes or aliases instead of full text, which your code can then map to the full content. You can also use inline comments within your prompt to guide the model's reasoning without it appearing in the final output.\n\nIf you remember one thing from this session:\nEngineer your system to let the LLM do what it does best (reasoning) and let code do what it does best (logic and structure). This system-level approach is the key to building cost-effective, scalable, and reliable AI applications.\n\nOur next session on July 15th 2025 will be all about \"Generating AI powered Content with LLMs\" \u2013 exploring how to use LLMs to generate content for various use cases.\nSign up here: https://lu.ma/ai-that-works-12\n\nIf you have any questions, reply to this email or ask on Discord: https://www.boundaryml.com/discord. We read every message! Happy coding \ud83e\uddd1\u200d\ud83d\udcbb\n\nVaibhav & Dex", "call_to_action": "Sign up here: https://lu.ma/ai-that-works-12"}